# 爬虫
- 框架：Scrapy
- 分布式： Scrapy-Redis
- 库：urllib，urllib2，requests
- 解析：XPath，lxml，bs4，re
- 应对反爬：User-Agent，Cookies，Referer，代理IP，第三方验证码打码平台，限速访问，模拟登陆
- 渲染JS：Selenium，PhantomJS，Chrome-Driver
- 架构：master + slave，redis管理url队列

# 数据可视化
- 前端：Echarts，Ajax，jQuery, Bootstrap，服务端渲染
- 后端：Django，MongoDB
- 数据分析：Numpy，Pandas

# 商城：
- 前端：jQuery，Ajax，Bootstrap，服务端渲染
- 后端：Nginx，Django，MySQL，Redis，uWSGI/Gunicorn，Celery，Whoosh，jieba
- 登录注册模块：使用Ajax实现登录注册功能。
- 购物车模块：使用Redis实现购物车模块
- 商品列表页和商品详情页和首页：由于频繁访问，所以缓存在Redis，并设置过期时间。过期以后，从数据库读取。
- 订单模块：使用事务实现订单提交操作，保证操作原子性。
- 个人中心模块：服务端渲染。
- 异步发送邮件：使用Celery消息队列完成异步发送邮件的任务。
- 搜索引擎：Haystack + Whoosh + jieba分词。
- 评论模块：Ajax实现评论功能。
- 商城即时通信系统(IM)：使用tornado的websocket模块实现即时通信功能。

# 租房：
- 前端：jQuery，Ajax，Template.js，Bootstrap，前后端分离，前端渲染
- 后端：Nginx，Tornado，Redis，MySQL，七牛云，云通讯
- 短信：使用云通讯第三方服务发送短信验证码。
- CDN：使用七牛云上传个人信息图片和房屋图片。
- 登录注册功能：使用Ajax实现，并在前端跳转。
- Session：使用Redis存储session数据。
- 图片验证码：使用第三方库Captcha
- 前端渲染：使用Template.js，使用Ajax获取服务端Api提供的json数据。
- 使用Redis缓存首页，商品列表页，商品详情页

# 技能点：
1，熟练掌握Python及其标准库。
2，熟练掌握Linux常用命令，熟悉Linux环境下的开发
3，熟悉前端技能：HTML/CSS/Javascript，jQuery，Bootstrap。熟悉template.js前端渲染模板的使用，熟悉前后端分离开发思想。了解ES6，Node.js，HTML5以及CSS3新特性。
4，熟练掌握Django框架开发网站，比如model设计，基于类的视图(CBV)和基于函数的视图(FBV)，比如xadmin等第三方django admin interface的使用，比如django的信号机制等。
5，熟练掌握MySQL的CRUD操作，熟练掌握Redis常用数据结构以及订阅发布(pub/sub)机制。熟悉MongoDB的使用。
6，了解Python数据分析常用包：Numpy，Pandas，Scikit-Learn。
7，了解搜索引擎的构建，比如使用Whoosh模块构建搜索引擎。
8，熟练掌握Scrapy框架及其分布式组件Scrapy-Redis。
9，熟练掌握使用re，lxml，bs4解析网页。
10，熟悉测试用例的编写，比如给Django项目编写测试用例。
11，熟悉Nginx的基本配置和使用。
12，熟悉阿里云服务器的部署。
13，熟悉第三方CDN厂商如七牛云的使用，熟悉使用云通讯发送短信验证码。
14，熟悉数据库表结构的设计和优化，比如建索引，分库分表。
15，熟悉HTTPS/HTTP协议，熟悉WebSocket协议，熟悉TCP/IP协议。
16，熟悉网站常见优化策略：缓存频繁访问的页面，对频繁查询的表的字段建索引，分库分表策略，优化SQL语句以及ORM的编写，使用CDN存储静态文件，使用Nginx做负载均衡，使用消息队列完成异步任务，使用异步IO框架如Tornado以及异步操作数据库的相关包如Tornado-MySQL，Tornado-Redis。
17，熟悉常见设计模式（如单例模式，工厂模式，生产者消费者模式，观察者模式）。
18，熟练使用Git管理项目，熟练使用PyCharm，Sublime，Vim编写程序，熟练使用Markdown编写产品文档。
19，熟练掌握多进程，多线程编程，深入理解协程异步IO的概念。
20，熟练使用Wireshark、HTTP Analyzer等抓包工具，有PC端、移动端的数据抓取经验。
21，熟练掌握使用Flask框架以及常用的插件开发网站，熟悉Flask插件机制。
22，熟练掌握Django REST framework开发RESTful API。
23，熟悉前后端分离思想，以及json web token的认证方式。
24，熟悉基于cookie和session的认证方式。
25，熟练使用echarts.js进行数据可视化。
26，熟悉RESTful。
27，熟悉sqlalchemy库，熟悉jinja2等模板引擎。
28，使用celery消息队列完成耗时操作比如异步发送邮件，使用celery消息队列完成定时任务，比如定时启动爬虫和定时更新数据库。
29，了解numpy，tensorflow的使用。


# 项目经验：
## 书城
- 项目名称：书城
- 开发环境：Ubuntu，PyCharm
- 项目架构：Django，MySQL，Redis，jQuery，Ajax，Bootstrap，Nginx，uWSGI
- 项目描述：快速开发一个书籍销售网站的雏形，主要分为前端书籍、详情、个人中心页面展示以及购物车和订单功能，还有管理后台的实现。
- 负责模块：静态页面抽象与缓存，登录注册模块，搜索模块，根据业务逻辑进行数据库表结构的设计，购物车模块，用户中心模块
- 用户中心： 用户中心有一个“最近浏览”，这个是一个频繁读取的操作，前期使用MySQL存储该数据发现效率低下，之后使用Redis缓存用户浏览记录，同理购物车的数据我们也存放在Redis中便于操作。
- 登录注册：用户注册时需要发送邮件(使用 itsdangerous 生成)或短信验证码(第三方服务)进行激活，当用户网速不足时会产生阻塞，因而此处使用Celery队列异步发送，保证用户体验。图形验证码早期使用Pillow自行绘制，后来换用第三方库 Captcha 实现。
- 购物车功能：由于频繁添加删除，所以不适合使用MySQL实现，我们使用Redis实现购物车功能。
- 订单功能：为保证操作的原子性，使用MySQL的事务来实现订单功能。
- 书籍列表页和详情页：使用Redis缓存频繁访问的页面。
- 项目收获：Django用于快速构建网站非常的方便，且有非常好用的ORM，还有很好的周边生态环境，对于Django作为同步框架的局限性，可以使用缓存，负载均衡等措施来规避，所以Django具有很好的开发体验。

## 租房
- 项目名称：租房网站
- 开发环境：Ubuntu，Sublime
- 项目架构：Tornado，MySQL，Redis，Nginx，jQuery，Ajax，Bootstrap，Template.js，云通讯，七牛云，前后端分离，Restful风格Api
- 项目描述：使用 Tornado 开发一个房屋出租网站，接口要求RESTful风格，前后端分离。前端使用 jQuery发送Ajax请求，后端返回Json数据，之后在页面使用template.js进行前端渲染。
- 负责模块：房屋信息，买家/卖家个人中心，订单管理，登录注册与验证，静态文件CDN加速
- 项目收获：使用Tornado这种异步非阻塞的Web框架，搭配Tornado-MySQL，Tornado-Redis异步IO第三方库，能够最大限度发挥Tornado的优势，提高并发处理效率。项目部署在阿里云上，比本地服务器部署更具备优势，维护成本也较低，能够实时监控服务器负载，数据库效率。

## 在线学习平台
- 项目名称：在线学习平台
- 开发环境：Ubuntu，PyCharm
- 项目架构：Django，MySQL，Redis，jQuery，Ajax，Bootstrap，Nginx，uWSGI, xadmin

## 生鲜
- 项目名称：生鲜
- 开发环境：Ubuntu，PyCharm
- 项目架构：Django，Djangorestframework，redis，vue全家桶，axios，mysql，redis，nginx，jwt
- 使用drf框架编写商城后台restful api，使用json web token鉴权，使用vue全家桶实现前端功能，前后端分离的架构。
- 使用djangorestframework-jwt插件实现鉴权功能。
- 使用云通讯实现发短信验证码功能
- 使用七牛云cdn存储图片。
- 使用redis缓存经常访问的页面，比如列表页和详情页。
- 使用xadmin第三方管理后台界面来做管理后台。


## 招聘网站爬取展示项目
- 项目名称：爬虫
- 开发环境：Ubuntu，PyCharm
- 项目架构：Scrapy, Scrapy-Redis, Celery, Django, MySQL/MongoDB, Redis, Echarts.js
- Scrapy: 爬取数据，数据清洗，数据持久化，请求头包装等。
- Scrapy-Redis: 调度和分发url队列，去重
- Celery：执行定时任务(启动爬虫，更新数据库)，基于redis
- MySQL/MongoDB: 持久化数据
- Echarts.js: 数据可视化
- Django：用来做展示数据的网站
- redis: 作为celery的broker来使用，以及作为scrapy-redis的urls消息队列和去重的缓存来使用。
- 分布式爬虫：一台redis机器作为scrapy-redis调度使用的机器，一台redis作为celery定时任务的机器，10台机器每台上面部署scrapy爬虫，一台机器上面部署django网站程序。一台机器部署MySQL/MongDB。
- 高匿代理ip池，模拟登陆，第三方打码，cookies。。。
- scrapy机器从redis机器的url队列中不停的lpop和lpush操作redis机器中的url队列。

```
        - - - - - - - -
        |    redis      |
        |  [url1, url2] |
        - - - - - - - -
        /                 \
    scrapy               scrapy
lpop: 从redis取要爬的url
lpush: 从页面里解析出来的url，再压入redis得url队列里面
redis机器做去重
随机分发
```

```python
# scrapy机器
while True:
    r = redis.RedisStrictConnection('redis://192.168.0.1:6379')
    try:
        url = r.lpop('urlqueue')
        yield Request(url, callback=parse)

        def parse():
            url = response.xpaht('//a')
            r.lpush(url)
    except:
        pass
```

## Flask社交网站
- 使用Flask以及相关插件开发一个社交网站。
- 比如Flask-Login，Flask-auth，Flask-script，Flask-sqlalchemy，Flask-moment，Flask-bootstrap等插件。
- 在页面样式上大多用Flask-bootstrap引入第三方cdn，这样就能大大减轻前端页面开发带来的成本
- 对于页面中的各种表单都使用Flask-form来进行设计处理
- 渲染模板方面用的是Jinjia2这个强大的模板引擎，它形式简单并且包含响应文本，所以我们认为它最适合Flask
- 使用Flask独有的蓝本解决程序工厂函数带来的路由复杂程度提升的问题
- 用户在程序中注册账户时，会被赋予适当的角色。因为我们专门设计了一张表来实现使用权限组织角色的功能，这样能让以后添加新角色时只需要使用不同的权限组合即可。管理员由保存在设置变量 FLASKY_ADMIN 中的电子邮件地址识别，只要这个电子 邮件地址出现在注册请求中，就会被赋予正确的角色。
- 使用flask-sqlalchemy orm来操作数据库。
- 后期将后端的api重构为了restful api，并使用flask-auth实现token鉴权的功能。